# coding: utf-8

import numpy as np
import scipy.sparse as sp
import theano.sparse as ts
import theano.tensor as tt
import theano
W_in = theano.shared(np.random.random(10, 100), name = 'w_in')
W_in = theano.shared(np.random.random(10, 100), name = 'w_in')
help(np.random.uniform)
W_in = theano.shared(np.random.uniform(-0.1, 0.1, (10, 100)), name = 'w_in')
W_rec = theano.shared(np.random.uniform(-0.1, 0.1, (100, 100)), name = 'w_rec')
W_out = theano.shared(np.random.uniform(-0.1, 0.1, (100, 5)), name = 'w_out')
X = tt.matrix(name = 'x')
y = tt.ivector(name = 'y')
X = tt.matrix(name = 'x', dtype=theano.config.floatX)
def recurrence(X_t, S_tm1):
    S = tt.dot(X_t, W_in) + tt.dot(S_tm1, W_rec)
    z = tt.dot(S, W_out)
    return S, z
recurrence_seq, _ = theano.scan(recurrence, sequences=[X], outputs_info=[tt.zeros(100, dtype=theano.config.floatX)])
def recurrence(X_t, S_tm1):
    S = tt.dot(X_t, W_in) + tt.dot(S_tm1, W_rec)
    z = tt.dot(S, W_out)
    return z, S
recurrence_seq, _ = theano.scan(recurrence, sequences=[X], outputs_info=[tt.zeros(100, dtype=theano.config.floatX)])
recurrence_seq, _ = theano.scan(recurrence, sequences=[X], outputs_info=[None, tt.zeros(100, dtype=theano.config.floatX)])
z = recurrence_seq[1]
help(tt.nnet.softmax)
zp = tt.nnet.softmax(z)
loss = tt.nnet.categorical_crossentropy(zp, y)
z_proc = theano.function([X, y], z)
z_proc = theano.function([X], z)
x = np.random.uniform(-1.0, 1.0, (5, 10))
x = np.random.uniform(-1.0, 1.0, (6, 10))
x
y
Y = tt.ivector(name = 'y')
loss = tt.nnet.categorical_crossentropy(zp, Y)
y = np.random.random_integers()
help(np.random.random_integers)
y = np.random.random_integers(0, 4, 6)
x
y
z_proc(x)
z_proc(x).shape
z = recurrence_seq[0]
zp = tt.nnet.softmax(z)
loss = tt.nnet.categorical_crossentropy(zp, Y)
z_proc = theano.function([X], z)
z_proc(x)
zp_proc = theano.function([X], zp)
zp_proc(x)
loss_proc = theano.function([X, Y], loss)
loss_proc(x)
loss_proc(x, y)
y = np.random.random_integers(0, 4, 6, dtype=int32)
y = np.random.random_integers(0, 4, 6, dtype=np.int32)
y = np.random.random_integers(0, 4, 6).asarray(dtype=np.int64)
y = np.random.random_integers(0, 4, 6).
y = np.random.random_integers(0, 4, 6)
y
y.astype
y = np.random.random_integers(0, 4, 6).astype(np.int64)
loss_proc(x, y)
y = np.random.random_integers(0, 4, 6).astype(np.int32)
y
loss_proc(x, y)
mean_loss = loss.mean()
mean_loss_proc = theano.function([X, Y], mean_loss)
mean_loss_proc(x, y)
import adadelta
optimizer = adadelta.ADADeltaUpdates()
optimizer
optimizer = adadelta.ADADeltaUpdates(verbose = 3)
param_list = [{'var' : W_in}, {'var' : W_rec}, {'var' : W_out}]
optimizer.make_updates(param_list)
optimizer = adadelta.ADADeltaUpdates(verbose = 3)
optimizer.make_updates(mean_loss, param_list)
train_proc = theano.function([X, Y], mean_loss, updates=optimizer.updates_)
train_proc(x, y)
train_proc(x, y)
train_proc(x, y)
train_proc(x, y)
train_proc(x, y)
train_proc(x, y)
train_proc(x, y)
train_proc(x, y)
train_proc(x, y)
train_proc(x, y)
train_proc(x, y)
train_proc(x, y)
train_proc(x, y)
train_proc(x, y)
train_proc(x, y)
train_proc(x, y)
train_proc(x, y)
train_proc(x, y)
train_proc(x, y)
train_proc(x, y)
train_proc(x, y)
train_proc(x, y)
train_proc(x, y)
train_proc(x, y)
train_proc(x, y)
train_proc(x, y)
train_proc(x, y)
train_proc(x, y)
train_proc(x, y)
train_proc(x, y)
train_proc(x, y)
train_proc(x, y)
train_proc(x, y)
train_proc(x, y)
train_proc(x, y)
zp_proc(x)
y
w_in0 = np.random.uniform(-0.1, 0.1, (10, 100)
)
w_rec0 = np.random.uniform(-0.1, 0.1, (100, 100))
w_out0 = np.random.uniform(-0.1, 0.1, (100, 5))
W_in.set_value(w_in0, borrow=False)
W_rec.set_value(w_rec0, borrow=False)
W_out.set_value(w_out0, borrow=False)
mean_loss_proc(x, y)
z_t, S_t = recurrence(X_t, S_tm1)
XX_t = tt.vector(name = 'xx_t', dtype=theano.config.floatX)
SS_tm1 = tt.vector(name = 'ss_tm1', dtype=theano.config.floatX)
zz_t, SS_t = recurrence(XX_t, SS_tm1)
zz_t_proc = theano.function([XX_t, SS_tm1], zz_t)
zz_t_proc(X[0], np.zeros(100))
zz_t_proc(x[0], np.zeros(100))
z_proc(x)
theano.gradient
import theano.gradient as tg
theano.subgraph_gradient
theano.subgraph_grad
loss
loss[-1]
gr_loss_wrt_w_out_last = theano.grad()
zzp_proc = theano.function([X], zzp)
zzp = tt.nnet.softmax(zz)
zzp_1 = tt.nnet.softmax(zz_t)
get_ipython().system(u'clear zzp_1')
del zzp_1
zzp_t = tt.nnet.softmax(zz_t)
zzp_t_proc = theano.function([X], zzp_t)
zzp_t_proc = theano.function([XX_t, SS_tm1], zzp_t)
zz_t_proc(X[0], np.zeros(100))
zz_t_proc(x[0], np.zeros(100))
zzp_t_proc(x[0], np.zeros(100))
zp_proc(x)
lloss_t = tt.nnet.categorical_crossentropy(zzp_t, Y_t)
YY_t = tt.iscalar(name = 'yy_t')
lloss_t = tt.nnet.categorical_crossentropy(zzp_t, YY_t)
YY_t = tt.ivector(name = 'yy_t')
lloss_t = tt.nnet.categorical_crossentropy(zzp_t, YY_t)
lloss_t_proc = theano.function([X, Y], lloss_t)
lloss_t_proc = theano.function([XX_t, YY_t], lloss_t)
lloss_t_proc = theano.function([XX_t, SS_tm1, YY_t], lloss_t)
zzp_t_proc(x[0], np.zeros(100), y[0])
zzp_t_proc(x[0], np.zeros(100), y[0])
yy_t = np.array(y[0])
yy_t
zzp_t_proc(x[0], np.zeros(100), yy_t)
yy_t = np.array([y[0]])
yy_t
zzp_t_proc(x[0], np.zeros(100), yy_t)
lloss_t = tt.nnet.categorical_crossentropy(zzp_t.reshape(1, -1), YY_t)
lloss_t = tt.nnet.categorical_crossentropy(zzp_t.reshape((1, -1)), YY_t)
lloss_t_proc = theano.function([XX_t, SS_tm1, YY_t], lloss_t)
lloss_t_proc
lloss_t_proc(x[0], np.zeros(100))
lloss_t_proc(x[0], np.zeros(100), yy_t)
loss_proc(x, y)
lloss_t = tt.nnet.categorical_crossentropy(zzp_t, YY_t)
lloss_t_proc = theano.function([XX_t, SS_tm1, YY_t], lloss_t)
lloss_t_proc(x[0], np.zeros(100), yy_t)
lloss_t_proc(x[0], np.zeros(100), y[0])
lloss_t_proc(x[0], np.zeros(100), yy_t)
s = recurrence_seq[1]
s_proc = theano.function([X], s)
 = recurrence_seq[1]
S = recurrence_seq[1]
S_proc = theano.function([X], S)
s = S_proc(X)
s = S_proc(x)
s
lloss_t_proc(x[-1], s[-1], yy_t)
lloss_t_proc(x[-1], s[-1], np.array([y[-1]]))
loss_proc(x, y)
z_proc(x)
zz_proc(x[-1], s[-1])
zz_t_proc(x[-1], s[-1])
zz_t_proc(x[-1], s[-2])
lloss_t_proc(x[-1], s[-2], np.array([y[-1]]))
loss_proc(x, y)
gr_lloss_wrt_w_rec_L = theano.grad(lloss_t, w_rec)
gr_lloss_wrt_W_rec_L = theano.grad(lloss_t, W_rec)
lloss_t = tt.nnet.categorical_crossentropy(zzp_t, YY_t)[0]
lloss_t_proc = (x[-1], s[-1], yy_t)
lloss_t_proc = theano.function([XX_t, SS_tm1, YY_t], lloss_t)
lloss_t_proc(x[-1], s[-1], yy_t)
lloss_t_proc(x[-1], s[-2], np.array([y[-1]]))
gr_lloss_wrt_W_rec_L = theano.grad(lloss_t, W_rec)
gr_lloss_wrt_W_rec_L_proc = theano.function([XX_t, SS_tm1, YY_t], gr_lloss_wrt_W_rec_L)
gr_lloss_wrt_W_rec_L(x[-1], s[-1], yy_t)
gr_lloss_wrt_W_rec_L_proc(x[-1], s[-1], yy_t)
gr_lloss_wrt_W_rec_L_proc(x[-1], s[-1], )
gr_lloss_wrt_W_rec_L_proc(x[-1], s[-2], np.array([y[-1]]))
gr_lloss_wrt_W_rec_L_proc(x[-2], s[-3], np.array([y[-2]]))
gr_lloss_wrt_W_rec_t = theano.grad(lloss_t, W_rec, known_grads={W_rec : gr_lloss_wrt_W_rec_tp1})
gr_lloss_wrt_W_rec_tp1 = tt.matrix(name = 'gr_lloss_wrt_W_rec_tp1', dtype=theano.config.floatX)
gr_lloss_wrt_W_rec_t = theano.grad(lloss_t, W_rec, known_grads={W_rec : gr_lloss_wrt_W_rec_tp1})
gr_lloss_wrt_W_rec_t_proc = theano.function([XX_t, SS_tm1, YY_t, gr_lloss_wrt_W_rec_tp1], gr_lloss_wrt_W_rec_t)
gr_lloss_wrt_W_rec_t = theano.grad(lloss_t, W_rec, known_grads={SS_t : gr_lloss_wrt_SS_t})
gr_lloss_wrt_SS_t = tt.matrix(name = 'gr_lloss_wrt_SS_t', dtype=theano.config.floatX)
gr_lloss_wrt_W_rec_t = theano.grad(lloss_t, W_rec, known_grads={SS_t : gr_lloss_wrt_SS_t})
gr_lloss_wrt_SS_t = tt.vector(name = 'gr_lloss_wrt_SS_t', dtype=theano.config.floatX)
gr_lloss_wrt_W_rec_t = theano.grad(lloss_t, W_rec, known_grads={SS_t : gr_lloss_wrt_SS_t})
gr_lloss_wrt_SS_bp = tt.vector(name = 'gr_lloss_wrt_SS_bp', dtype=theano.config.floatX)
gr_lloss_wrt_W_rec_t = theano.grad(lloss_t, W_rec, known_grads={SS_t : gr_lloss_wrt_SS_bp})
gr_lloss_wrt_SS_L = theano.grad(lloss_t, SS_t)
gr_lloss_wrt_SS_L_proc = theano.function([XX_t, SS_t, YY_t], gr_lloss_wrt_SS_L)
gr_lloss_wrt_SS_L_proc = theano.function([XX_t, SS_tm1, YY_t], gr_lloss_wrt_SS_L)
gr_lloss_wrt_W_rec_L_proc(x[-1], s[-2], np.array([y[-1]]))
gr_lloss_wrt_SS_L_proc(x[-1], s[-2], np.array([y[-1]]))
gbp = gr_lloss_wrt_SS_L_proc(x[-1], s[-2], np.array([y[-1]]))
gr_lloss_wrt_SS_L_proc(x[-1], s[-2], np.array([y[-1]]))
gr_lloss_wrt_SS_L_proc(x[-2], s[-3], np.array([y[-2]]))
gr_lloss_wrt_SS_t_proc(x[-2], s[-3], np.array([y[-2]]))
gr_lloss_wrt_W_rec_t = theano.grad(lloss_t, W_rec, known_grads={SS_t : gr_lloss_wrt_SS_bp})
gr_lloss_wrt_W_rec_t_proc = theano.function([XX_t, SS_tm1, YY_t], gr_lloss_wrt_W_rec_t)
gr_lloss_wrt_W_rec_t_proc = theano.function([XX_t, SS_tm1, YY_t], gr_lloss_wrt_W_rec_t)
gr_lloss_wrt_W_rec_t = theano.grad(lloss_t, W_rec, known_grads={SS_t : gr_lloss_wrt_SS_bp})
gr_lloss_wrt_W_rec_t_proc = theano.function([XX_t, SS_tm1, YY_t, gr_lloss_wrt_SS_bp], gr_lloss_wrt_W_rec_t)
gr_lloss_wrt_W_rec_t = theano.grad(lloss_t, W_rec, known_grads={SS_t : gr_lloss_wrt_SS_bp})
gr_lloss_wrt_SS_bp = tt.vector(name = 'gr_lloss_wrt_SS_bp', dtype=theano.config.floatX)
gr_lloss_wrt_W_rec_t = theano.grad(lloss_t, W_rec, known_grads={SS_t : gr_lloss_wrt_SS_bp})
gr_lloss_wrt_W_rec_t_proc = theano.function([XX_t, SS_tm1, YY_t, gr_lloss_wrt_SS_bp], gr_lloss_wrt_W_rec_t)
gr_lloss_wrt_W_rec_t_proc = theano.function([SS_tm1, YY_t, gr_lloss_wrt_SS_bp], gr_lloss_wrt_W_rec_t)
gr_lloss_wrt_W_rec_t_proc = theano.function([SS_tm1, gr_lloss_wrt_SS_bp], gr_lloss_wrt_W_rec_t)
gr_lloss_wrt_W_rec_L_proc(x[-1], s[-2], np.array([y[-1]]))
gr_lloss_wrt_W_rec_t_proc(gbp[-2])
gr_lloss_wrt_W_rec_t_proc(gbp)
gr_lloss_wrt_W_rec_t_proc(xx_t[-3] gbp)
gr_lloss_wrt_W_rec_t_proc(xx_t[-3], gbp)
gr_lloss_wrt_W_rec_t_proc(x[-3], gbp)
help(%save)
help(save)
get_ipython().magic(u'save')
get_ipython().magic(u'save rnn_bptt.py 0-243')